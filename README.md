# ğŸš¢ PrevisÃ£o de SobrevivÃªncia no Titanic (Kaggle)

Este projeto implementa um pipeline completo de Machine Learning para prever a sobrevivÃªncia dos passageiros do Titanic, conforme o desafio clÃ¡ssico do Kaggle. O objetivo Ã© aplicar tÃ©cnicas de engenharia de features (feature engineering) e encontrar os melhores hiperparÃ¢metros para um modelo `RandomForestClassifier`.

O script realiza todo o processo: carregamento, limpeza, transformaÃ§Ã£o, engenharia de features, busca de hiperparÃ¢metros (simplificada) e treinamento final para gerar o arquivo de submissÃ£o.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral do Projeto](#-visÃ£o-geral-do-projeto)
- [Funcionalidades](#-funcionalidades)
- [Metodologia do Pipeline de ML](#-metodologia-do-pipeline-de-ml)
- [Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [Como Executar](#-como-executar)
- [Estrutura do CÃ³digo](#-estrutura-do-cÃ³digo)
- [SaÃ­das Geradas](#-saÃ­das-geradas)
- [Autor](#-autor)

## ğŸ¯ VisÃ£o Geral do Projeto

O script simula o fluxo de trabalho de um cientista de dados para resolver o desafio do Titanic. Ele lÃª os dados brutos de treino e teste, aplica uma sÃ©rie de transformaÃ§Ãµes e cria novas features relevantes (como `FamilySize`, `Title`, `Deck`, etc.) para melhorar o poder preditivo do modelo.

O diferencial deste script Ã© a funÃ§Ã£o `preprocess` unificada, que garante que tanto os dados de treino quanto os de teste passem exatamente pelas mesmas transformaÃ§Ãµes, evitando vazamento de dados (data leakage) e inconsistÃªncias. AlÃ©m disso, ele implementa uma busca simples por hiperparÃ¢metros para otimizar o `RandomForestClassifier`.

## âœ¨ Funcionalidades

- **Pipeline de PrÃ©-processamento:** Uma funÃ§Ã£o centralizada `preprocess` trata valores ausentes, converte dados categÃ³ricos e limpa colunas.
- **Engenharia de Features (Feature Engineering):** CriaÃ§Ã£o de mais de 10 novas features, incluindo:
  - `FamilySize` e `IsAlone` (baseado em `SibSp` e `Parch`)
  - `Title` (extraÃ­do do nome)
  - `Deck` (extraÃ­do da cabine)
  - `IsChild` e `IsMother` (baseado em idade, sexo e parentes)
  - `FarePerPerson` (tarifa dividida pelo tamanho da famÃ­lia)
  - `ClassFareInteraction` (interaÃ§Ã£o Pclass * Fare)
  - `AgeBin` e `FareBin` (discretizaÃ§Ã£o de idade e tarifa)
- **Busca de HiperparÃ¢metros:** Testa automaticamente diferentes combinaÃ§Ãµes de `n_estimators` e `max_depth` para encontrar o `RandomForestClassifier` com melhor acurÃ¡cia em um conjunto de validaÃ§Ã£o.
- **Treinamento Otimizado:** Treina o modelo final com todos os dados de treino usando os melhores parÃ¢metros encontrados na etapa de validaÃ§Ã£o.
- **GeraÃ§Ã£o de SubmissÃ£o:** Produz o arquivo `submission.csv` no formato exigido pelo Kaggle.

## ğŸ² Metodologia do Pipeline de ML

1.  **Carregamento:** Os dados de `train.csv` e `test.csv` sÃ£o carregados em DataFrames `pandas`.
2.  **AnÃ¡lise ExploratÃ³ria:** Uma verificaÃ§Ã£o rÃ¡pida da taxa de sobrevivÃªncia por sexo Ã© impressa no console.
3.  **PrÃ©-processamento e Feature Engineering:** A funÃ§Ã£o `preprocess` Ã© aplicada a ambos os conjuntos de dados. Ela executa toda a limpeza (ex: `fillna` para `Age` e `Fare`) e a criaÃ§Ã£o de novas features.
4.  **Alinhamento de Colunas:** O script garante que o conjunto de teste tenha exatamente as mesmas colunas (dummies) que o conjunto de treino.
5.  **ValidaÃ§Ã£o (Grid Search Simplificado):** Os dados de treino sÃ£o divididos (`train_test_split`) em treino e validaÃ§Ã£o (80/20). Um loop `for` aninhado testa diferentes `n_estimators` e `max_depth`, treinando no subconjunto de treino e medindo a acurÃ¡cia no de validaÃ§Ã£o.
6.  **SeleÃ§Ã£o do Melhor Modelo:** A combinaÃ§Ã£o de parÃ¢metros com a maior acurÃ¡cia de validaÃ§Ã£o Ã© armazenada.
7.  **Treinamento Final:** Um novo modelo `RandomForestClassifier` Ã© instanciado com os melhores parÃ¢metros e treinado usando **todos** os dados de treino (`X` e `y`).
8.  **PrevisÃ£o:** O modelo final Ã© usado para gerar previsÃµes no conjunto de teste (`X_test`).
9.  **GeraÃ§Ã£o do Arquivo:** As previsÃµes sÃ£o salvas no formato `PassengerId`, `Survived` no arquivo `submission.csv`.

## ğŸ› ï¸ Tecnologias Utilizadas

- **Linguagem:** Python 3
- **Bibliotecas Principais:**
  - `pandas`: Para manipulaÃ§Ã£o e anÃ¡lise dos dados.
  - `scikit-learn`: Para o modelo (`RandomForestClassifier`), divisÃ£o de dados (`train_test_split`) e mÃ©tricas (`accuracy_score`).
  - `sys`: Para configurar o encoding de saÃ­da para UTF-8.

## âš™ï¸ PrÃ©-requisitos

Antes de executar, vocÃª precisa ter o Python 3 instalado e as seguintes bibliotecas. VocÃª pode instalÃ¡-las com pip:

```bash
pip install pandas scikit-learn
```

AlÃ©m disso, vocÃª precisarÃ¡ dos arquivos de dados do Kaggle (`train.csv` e `test.csv`) em um subdiretÃ³rio chamado `DesafioTitanic/`.

**Estrutura de arquivos esperada:**
```
â”œâ”€â”€ DesafioTitanic/
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ gender_submission.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ main.py (este cÃ³digo)
â””â”€â”€ README.md
```

## ğŸš€ Como Executar

1.  **Clone o repositÃ³rio** ou salve o arquivo do projeto (`main.py`) em um diretÃ³rio local.
2.  **Crie o diretÃ³rio `DesafioTitanic/`** no mesmo nÃ­vel do script.
3.  **Baixe os arquivos `train.csv` e `test.csv`** do Kaggle e coloque-os dentro de `DesafioTitanic/`.
4.  **Instale as dependÃªncias** conforme listado na seÃ§Ã£o de prÃ©-requisitos.
5.  **Execute o script** principal via terminal:
    ```bash
    python main.py.py
    ```
6.  Aguarde a execuÃ§Ã£o. O script imprimirÃ¡ os resultados da busca de hiperparÃ¢metros no console. Ao final, vocÃª verÃ¡ a seguinte mensagem (se a Ãºltima linha do script for descomentada):
    ```
    Arquivo 'submission.csv' criado com sucesso!
    ```

## ğŸ“‚ Estrutura do CÃ³digo

O script Ã© organizado nas seguintes seÃ§Ãµes:

-   **ImportaÃ§Ã£o de bibliotecas:** Importa `pandas`, `sklearn` e `sys`.
-   **ConfiguraÃ§Ã£o de Encoding:** Garante que a saÃ­da do console use UTF-8.
-   **Carregamento dos dados:** LÃª os arquivos `train.csv` e `test.csv`.
-   **AnÃ¡lise ExploratÃ³ria:** ImpressÃ£o da taxa de sobrevivÃªncia por sexo.
-   **FunÃ§Ã£o `preprocess`:** DefiniÃ§Ã£o da funÃ§Ã£o principal de prÃ©-processamento e engenharia de features.
-   **AplicaÃ§Ã£o do PrÃ©-processamento:** Chamada da funÃ§Ã£o `preprocess` para `train_data` e `test_data`.
-   **Alinhamento de Colunas:** Garante que os DataFrames de treino e teste tenham as mesmas colunas apÃ³s o `get_dummies`.
-   **DefiniÃ§Ã£o de Features:** Seleciona a lista final de colunas a serem usadas no modelo.
-   **SeparaÃ§Ã£o para ValidaÃ§Ã£o:** Divide os dados de treino com `train_test_split`.
-   **Busca de HiperparÃ¢metros:** Loop `for` aninhado que testa `n_estimators` e `max_depth`.
-   **Treinamento do Modelo Final:** Treina o modelo com os melhores parÃ¢metros em todos os dados de treino.
-   **GeraÃ§Ã£o das PrevisÃµes:** Usa o modelo final para prever `test_data`.
-   **CriaÃ§Ã£o do Arquivo de SubmissÃ£o:** Salva os resultados no DataFrame `output`.

## ğŸ“„ SaÃ­das Geradas

Ao executar o script, os seguintes arquivos serÃ£o criados (assumindo que a Ãºltima linha seja descomentada):

-   `submission.csv`: O arquivo final pronto para ser enviado ao Kaggle, contendo o `PassengerId` e a previsÃ£o `Survived` (0 ou 1).

AlÃ©m disso, o console exibirÃ¡:

-   O `head()` dos DataFrames de treino e teste.
-   A porcentagem de sobrevivÃªncia de homens e mulheres.
-   A lista de features usadas no modelo.
-   A acurÃ¡cia de cada combinaÃ§Ã£o de hiperparÃ¢metro testada.
-   A melhor combinaÃ§Ã£o de parÃ¢metros encontrada e sua acurÃ¡cia.

## ğŸ‘¨â€ğŸ’» Autor

- **Kevin Thiago dos Santos** - *Estudante de CiÃªncia da ComputaÃ§Ã£o*
